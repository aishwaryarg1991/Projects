package com.sundogsoftware.spark

import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.log4j._

object ScalaLearning2 {
  
  def main(args: Array[String]) {
    
    Logger.getLogger("org").setLevel(Level.ERROR)
   
     val sc = new SparkContext("local[*]","FriendsByAge")
    val lines = sc.textFile("c:/SparkScala/fakefriends.csv")
    val age = lines.map(x => x.toString().split(",")(2).toInt)
    val friends = lines.map(x => x.toString().split(",")(3).toInt)
    val tup= (age,friends)
   val totalsByAge = tup.mapValues(x => (x, 1)).reduceByKey( (x,y) => (x._1 + y._1, x._2 + y._2))
    
     //val fields = lines.map(x=>x.split(","))
  //   val fields = line.split(",")
  //   val age = fields(2).toInt
    //  val numFriends = fields(3).toInt
   // val results = fields.countByValue()
    //  val sortedResults = results.toSeq.sortBy(_._1)
      tup.foreach(println)
       
      
  
    
  }
	 
}